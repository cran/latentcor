<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Mingze Huang, Christian L. Müller, Irina Gaynanova" />

<meta name="date" content="2025-11-18" />

<title>Mathematical Framework for latentcor</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<style type="text/css">

div.csl-bib-body { }
div.csl-entry {
clear: both;
margin-bottom: 0em;
}
.hanging div.csl-entry {
margin-left:2em;
text-indent:-2em;
}
div.csl-left-margin {
min-width:2em;
float:left;
}
div.csl-right-inline {
margin-left:2em;
padding-left:1em;
}
div.csl-indent {
margin-left: 2em;
}
</style>

<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Mathematical Framework for latentcor</h1>
<h4 class="author">Mingze Huang, Christian L. Müller, Irina
Gaynanova</h4>
<h4 class="date">2025-11-18</h4>



<div id="latent-gaussian-copula-model-for-mixed-data" class="section level1">
<h1>Latent Gaussian Copula Model for Mixed Data</h1>
<p><code>latentcor</code> utilizes the powerful semi-parametric latent
Gaussian copula models to estimate latent correlations between mixed
data types (continuous/binary/ternary/truncated or zero-inflated). Below
we review the definitions for each type.</p>
<p><strong><em>Definition of continuous model</em></strong> <span class="citation">(Fan et al. 2017)</span></p>
<p>A random <span class="math inline">\(X\in\cal{R}^{p}\)</span>
satisfies the Gaussian copula (or nonparanormal) model if there exist
monotonically increasing <span class="math inline">\(f=(f_{j})_{j=1}^{p}\)</span> with <span class="math inline">\(Z_{j}=f_{j}(X_{j})\)</span> satisfying <span class="math inline">\(Z\sim N_{p}(0, \Sigma)\)</span>, <span class="math inline">\(\sigma_{jj}=1\)</span>; we denote <span class="math inline">\(X\sim NPN(0, \Sigma, f)\)</span>.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a>X <span class="ot">=</span> <span class="fu">gen_data</span>(<span class="at">n =</span> <span class="dv">6</span>, <span class="at">types =</span> <span class="st">&quot;con&quot;</span>)<span class="sc">$</span>X</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a>X</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="co">#&gt;            [,1]</span></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="co">#&gt; [1,]  0.2949394</span></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="co">#&gt; [2,] -1.3428070</span></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="co">#&gt; [3,] -0.7989761</span></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="co">#&gt; [4,]  0.2237552</span></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a><span class="co">#&gt; [5,]  0.8093799</span></span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a><span class="co">#&gt; [6,]  0.8812656</span></span></code></pre></div>
<p><strong><em>Definition of binary model</em></strong> <span class="citation">(Fan et al. 2017)</span></p>
<p>A random <span class="math inline">\(X\in\cal{R}^{p}\)</span>
satisfies the binary latent Gaussian copula model if there exists <span class="math inline">\(W\sim NPN(0, \Sigma, f)\)</span> such that <span class="math inline">\(X_{j}=I(W_{j}&gt;c_{j})\)</span>, where <span class="math inline">\(I(\cdot)\)</span> is the indicator function and
<span class="math inline">\(c_{j}\)</span> are constants.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a>X <span class="ot">=</span> <span class="fu">gen_data</span>(<span class="at">n =</span> <span class="dv">6</span>, <span class="at">types =</span> <span class="st">&quot;bin&quot;</span>)<span class="sc">$</span>X</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>X</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a><span class="co">#&gt;      [,1]</span></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a><span class="co">#&gt; [1,]    1</span></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a><span class="co">#&gt; [2,]    0</span></span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a><span class="co">#&gt; [3,]    1</span></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a><span class="co">#&gt; [4,]    1</span></span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a><span class="co">#&gt; [5,]    0</span></span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a><span class="co">#&gt; [6,]    0</span></span></code></pre></div>
<p><strong><em>Definition of ternary model</em></strong> <span class="citation">(Quan, Booth, and Wells 2018)</span></p>
<p>A random <span class="math inline">\(X\in\cal{R}^{p}\)</span>
satisfies the ternary latent Gaussian copula model if there exists <span class="math inline">\(W\sim NPN(0, \Sigma, f)\)</span> such that <span class="math inline">\(X_{j}=I(W_{j}&gt;c_{j})+I(W_{j}&gt;c&#39;_{j})\)</span>,
where <span class="math inline">\(I(\cdot)\)</span> is the indicator
function and <span class="math inline">\(c_{j}&lt;c&#39;_{j}\)</span>
are constants.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>X <span class="ot">=</span> <span class="fu">gen_data</span>(<span class="at">n =</span> <span class="dv">6</span>, <span class="at">types =</span> <span class="st">&quot;ter&quot;</span>)<span class="sc">$</span>X</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>X</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a><span class="co">#&gt;      [,1]</span></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a><span class="co">#&gt; [1,]    0</span></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a><span class="co">#&gt; [2,]    1</span></span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a><span class="co">#&gt; [3,]    0</span></span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a><span class="co">#&gt; [4,]    1</span></span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a><span class="co">#&gt; [5,]    1</span></span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a><span class="co">#&gt; [6,]    2</span></span></code></pre></div>
<p><strong><em>Definition of truncated or zero-inflated
model</em></strong> <span class="citation">(Yoon, Carroll, and Gaynanova
2020)</span></p>
<p>A random <span class="math inline">\(X\in\cal{R}^{p}\)</span>
satisfies the truncated latent Gaussian copula model if there exists
<span class="math inline">\(W\sim NPN(0, \Sigma, f)\)</span> such that
<span class="math inline">\(X_{j}=I(W_{j}&gt;c_{j})W_{j}\)</span>, where
<span class="math inline">\(I(\cdot)\)</span> is the indicator function
and <span class="math inline">\(c_{j}\)</span> are constants.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a>X <span class="ot">=</span> <span class="fu">gen_data</span>(<span class="at">n =</span> <span class="dv">6</span>, <span class="at">types =</span> <span class="st">&quot;tru&quot;</span>)<span class="sc">$</span>X</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>X</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a><span class="co">#&gt;            [,1]</span></span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a><span class="co">#&gt; [1,] 0.00000000</span></span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a><span class="co">#&gt; [2,] 0.60456858</span></span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a><span class="co">#&gt; [3,] 2.40780850</span></span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a><span class="co">#&gt; [4,] 0.00000000</span></span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a><span class="co">#&gt; [5,] 0.00000000</span></span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a><span class="co">#&gt; [6,] 0.04778851</span></span></code></pre></div>
<p><strong><em>Mixed latent Gaussian copula model</em></strong></p>
<p>The mixed latent Gaussian copula model jointly models <span class="math inline">\(W=(W_{1}, W_{2}, W_{3}, W_{4})\sim NPN(0, \Sigma,
f)\)</span> such that <span class="math inline">\(X_{1j}=W_{1j}\)</span>, <span class="math inline">\(X_{2j}=I(W_{2j}&gt;c_{2j})\)</span>, <span class="math inline">\(X_{3j}=I(W_{3j}&gt;c_{3j})+I(W_{3j}&gt;c&#39;_{3j})\)</span>
and <span class="math inline">\(X_{4j}=I(W_{4j}&gt;c_{4j})W_{4j}\)</span>.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="st">&quot;234820&quot;</span>)</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>X <span class="ot">=</span> <span class="fu">gen_data</span>(<span class="at">n =</span> <span class="dv">100</span>, <span class="at">types =</span> <span class="fu">c</span>(<span class="st">&quot;con&quot;</span>, <span class="st">&quot;bin&quot;</span>, <span class="st">&quot;ter&quot;</span>, <span class="st">&quot;tru&quot;</span>))<span class="sc">$</span>X</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a><span class="fu">head</span>(X)</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a><span class="co">#&gt;            [,1] [,2] [,3]      [,4]</span></span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a><span class="co">#&gt; [1,] -0.2780040    0    0 0.0000000</span></span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a><span class="co">#&gt; [2,] -0.8939372    0    0 0.0000000</span></span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a><span class="co">#&gt; [3,]  0.3838027    1    1 0.3857133</span></span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a><span class="co">#&gt; [4,] -1.8276629    1    2 0.0000000</span></span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a><span class="co">#&gt; [5,] -0.7248362    0    1 0.0000000</span></span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a><span class="co">#&gt; [6,] -0.8752912    0    0 0.0000000</span></span></code></pre></div>
</div>
<div id="moment-based-estimation-of-sigma-based-on-bridge-functions" class="section level1">
<h1>Moment-based estimation of <span class="math inline">\(\Sigma\)</span> based on bridge functions</h1>
<p>The estimation of latent correlation matrix <span class="math inline">\(\Sigma\)</span> is achieved via the <strong>bridge
function</strong> <span class="math inline">\(F\)</span> which is
defined such that <span class="math inline">\(E(\hat{\tau}_{jk})=F(\sigma_{jk})\)</span>, where
<span class="math inline">\(\sigma_{jk}\)</span> is the latent
correlation between variables <span class="math inline">\(j\)</span> and
<span class="math inline">\(k\)</span>, and <span class="math inline">\(\hat{\tau}_{jk}\)</span> is the corresponding
sample Kendall’s <span class="math inline">\(\tau\)</span>.</p>
<p><strong><em>Kendall’s <span class="math inline">\(\tau\)</span>
(<span class="math inline">\(\tau_{a}\)</span>)</em></strong></p>
<p>Given observed <span class="math inline">\(\mathbf{x}_{j},
\mathbf{x}_{k}\in\cal{R}^{n}\)</span>,</p>
<p><span class="math display">\[
\hat{\tau}_{jk}=\hat{\tau}(\mathbf{x}_{j},
\mathbf{x}_{k})=\frac{2}{n(n-1)}\sum_{1\le i&lt;i&#39;\le
n}sign(x_{ij}-x_{i&#39;j})sign(x_{ik}-x_{i&#39;k}),
\]</span> where <span class="math inline">\(n\)</span> is the sample
size.</p>
<p><code>latentcor</code> calculates pairwise Kendall’s <span class="math inline">\(\widehat \tau\)</span> as part of the estimation
process</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>estimate <span class="ot">=</span> <span class="fu">latentcor</span>(X, <span class="at">types =</span> <span class="fu">c</span>(<span class="st">&quot;con&quot;</span>, <span class="st">&quot;bin&quot;</span>, <span class="st">&quot;ter&quot;</span>, <span class="st">&quot;tru&quot;</span>))</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>K <span class="ot">=</span> estimate<span class="sc">$</span>K</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>K</span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a><span class="co">#&gt;           [,1]      [,2]      [,3]      [,4]</span></span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a><span class="co">#&gt; [1,] 1.0000000 0.1826263 0.2347475 0.2963636</span></span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a><span class="co">#&gt; [2,] 0.1826263 1.0000000 0.2121212 0.1866667</span></span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a><span class="co">#&gt; [3,] 0.2347475 0.2121212 1.0000000 0.2842424</span></span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a><span class="co">#&gt; [4,] 0.2963636 0.1866667 0.2842424 1.0000000</span></span></code></pre></div>
<p>Using <span class="math inline">\(F\)</span> and <span class="math inline">\(\widehat \tau_{jk}\)</span>, a moment-based
estimator is <span class="math inline">\(\hat{\sigma}_{jk}=F^{-1}(\hat{\tau}_{jk})\)</span>
with the corresponding <span class="math inline">\(\hat{\Sigma}\)</span>
being consistent for <span class="math inline">\(\Sigma\)</span> <span class="citation">(Fan et al. 2017; Quan, Booth, and Wells 2018; Yoon,
Carroll, and Gaynanova 2020)</span>.</p>
<p>The explicit form of <strong>bridge function</strong> <span class="math inline">\(F\)</span> has been derived for all combinations
of continuous(C)/binary(B)/ternary(N)/truncated(T) variable types, and
we summarize the corresponding references. Each of this combinations is
implemented in <code>latentcor</code>.</p>
<table>
<colgroup>
<col width="11%" />
<col width="22%" />
<col width="22%" />
<col width="22%" />
<col width="22%" />
</colgroup>
<thead>
<tr class="header">
<th>Type</th>
<th>continuous</th>
<th>binary</th>
<th>ternary</th>
<th>zero-inflated (truncated)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>continuous</td>
<td><span class="citation">Liu, Lafferty, and Wasserman
(2009)</span></td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
<tr class="even">
<td>binary</td>
<td><span class="citation">Fan et al. (2017)</span></td>
<td><span class="citation">Fan et al. (2017)</span></td>
<td>-</td>
<td>-</td>
</tr>
<tr class="odd">
<td>ternary</td>
<td><span class="citation">Quan, Booth, and Wells (2018)</span></td>
<td><span class="citation">Quan, Booth, and Wells (2018)</span></td>
<td><span class="citation">Quan, Booth, and Wells (2018)</span></td>
<td>-</td>
</tr>
<tr class="even">
<td>zero-inflated (truncated)</td>
<td><span class="citation">Yoon, Carroll, and Gaynanova
(2020)</span></td>
<td><span class="citation">Yoon, Carroll, and Gaynanova
(2020)</span></td>
<td>See Appendix</td>
<td><span class="citation">Yoon, Carroll, and Gaynanova
(2020)</span></td>
</tr>
</tbody>
</table>
<p>Below we provide an explicit form of <span class="math inline">\(F\)</span> for each combination.</p>
<p><strong>Theorem (explicit form of bridge function)</strong> Let <span class="math inline">\(W_{1}\in\cal{R}^{p_{1}}\)</span>, <span class="math inline">\(W_{2}\in\cal{R}^{p_{2}}\)</span>, <span class="math inline">\(W_{3}\in\cal{R}^{p_{3}}\)</span>, <span class="math inline">\(W_{4}\in\cal{R}^{p_{4}}\)</span> be such that
<span class="math inline">\(W=(W_{1}, W_{2}, W_{3}, W_{4})\sim NPN(0,
\Sigma, f)\)</span> with <span class="math inline">\(p=p_{1}+p_{2}+p_{3}+p_{4}\)</span>. Let <span class="math inline">\(X=(X_{1}, X_{2}, X_{3},
X_{4})\in\cal{R}^{p}\)</span> satisfy <span class="math inline">\(X_{j}=W_{j}\)</span> for <span class="math inline">\(j=1,...,p_{1}\)</span>, <span class="math inline">\(X_{j}=I(W_{j}&gt;c_{j})\)</span> for <span class="math inline">\(j=p_{1}+1, ..., p_{1}+p_{2}\)</span>, <span class="math inline">\(X_{j}=I(W_{j}&gt;c_{j})+I(W_{j}&gt;c&#39;_{j})\)</span>
for <span class="math inline">\(j=p_{1}+p_{2}+1, ..., p_{3}\)</span> and
<span class="math inline">\(X_{j}=I(W_{j}&gt;c_{j})W_{j}\)</span> for
<span class="math inline">\(j=p_{1}+p_{2}+p_{3}+1, ..., p\)</span> with
<span class="math inline">\(\Delta_{j}=f(c_{j})\)</span>. The rank-based
estimator of <span class="math inline">\(\Sigma\)</span> based on the
observed <span class="math inline">\(n\)</span> realizations of <span class="math inline">\(X\)</span> is the matrix <span class="math inline">\(\mathbf{\hat{R}}\)</span> with <span class="math inline">\(\hat{r}_{jj}=1\)</span>, <span class="math inline">\(\hat{r}_{jk}=\hat{r}_{kj}=F^{-1}(\hat{\tau}_{jk})\)</span>
with block structure</p>
<p><span class="math display">\[
\mathbf{\hat{R}}=\begin{pmatrix}
F_{CC}^{-1}(\hat{\tau}) &amp; F_{CB}^{-1}(\hat{\tau}) &amp;
F_{CN}^{-1}(\hat{\tau}) &amp; F_{CT}^{-1}(\hat{\tau})\\
F_{BC}^{-1}(\hat{\tau}) &amp; F_{BB}^{-1}(\hat{\tau}) &amp;
F_{BN}^{-1}(\hat{\tau}) &amp; F_{BT}^{-1}(\hat{\tau})\\
F_{NC}^{-1}(\hat{\tau}) &amp; F_{NB}^{-1}(\hat{\tau}) &amp;
F_{NN}^{-1}(\hat{\tau}) &amp; F_{NT}^{-1}(\hat{\tau})\\
F_{TC}^{-1}(\hat{\tau}) &amp; F_{TB}^{-1}(\hat{\tau}) &amp;
F_{TN}^{-1}(\hat{\tau}) &amp; F_{TT}^{-1}(\hat{\tau})
\end{pmatrix}
\]</span> <span class="math display">\[
F(\cdot)=\begin{cases}
CC:\ 2\sin^{-1}(r)/\pi \\
\\
BC: \ 4\Phi_{2}(\Delta_{j},0;r/\sqrt{2})-2\Phi(\Delta_{j}) \\
\\
BB: \
2\{\Phi_{2}(\Delta_{j},\Delta_{k};r)-\Phi(\Delta_{j})\Phi(\Delta_{k})\}  \\
\\
NC: \
4\Phi_{2}(\Delta_{j}^{2},0;r/\sqrt{2})-2\Phi(\Delta_{j}^{2})+4\Phi_{3}(\Delta_{j}^{1},\Delta_{j}^{2},0;\Sigma_{3a}(r))-2\Phi(\Delta_{j}^{1})\Phi(\Delta_{j}^{2})\\
\\
NB: \
2\Phi_{2}(\Delta_{j}^{2},\Delta_{k},r)\{1-\Phi(\Delta_{j}^{1})\}-2\Phi(\Delta_{j}^{2})\{\Phi(\Delta_{k})-\Phi_{2}(\Delta_{j}^{1},\Delta_{k},r)\}
\\
\\
NN: \
2\Phi_{2}(\Delta_{j}^{2},\Delta_{k}^{2};r)\Phi_{2}(-\Delta_{j}^{1},-\Delta_{k}^{1};r)-2\{\Phi(\Delta_{j}^{2})-\Phi_{2}(\Delta_{j}^{2},\Delta_{k}^{1};r)\}\{\Phi(\Delta_{k}^{2})-\Phi_{2}(\Delta_{j}^{1},\Delta_{k}^{2};r)\}
\\
\\
TC: \
-2\Phi_{2}(-\Delta_{j},0;1/\sqrt{2})+4\Phi_{3}(-\Delta_{j},0,0;\Sigma_{3b}(r))
\\
\\
TB: \
2\{1-\Phi(\Delta_{j})\}\Phi(\Delta_{k})-2\Phi_{3}(-\Delta_{j},\Delta_{k},0;\Sigma_{3c}(r))-2\Phi_{3}(-\Delta_{j},\Delta_{k},0;\Sigma_{3d}(r))  \\
\\
TN: \ -2\Phi(-\Delta_{k}^{1})\Phi(\Delta_{k}^{2}) +
2\Phi_{3}(-\Delta_{k}^{1},\Delta_{k}^{2},\Delta_{j};\Sigma_{3e}(r))+2\Phi_{4}(-\Delta_{k}^{1},\Delta_{k}^{2},-\Delta_{j},0;\Sigma_{4a}(r))+2\Phi_{4}(-\Delta_{k}^{1},\Delta_{k}^{2},-\Delta_{j},0;\Sigma_{4b}(r))
\\
\\
TT: \
-2\Phi_{4}(-\Delta_{j},-\Delta_{k},0,0;\Sigma_{4c}(r))+2\Phi_{4}(-\Delta_{j},-\Delta_{k},0,0;\Sigma_{4d}(r))
\\
\end{cases}
\]</span></p>
<p>where <span class="math inline">\(\Delta_{j}=\Phi^{-1}(\pi_{0j})\)</span>, <span class="math inline">\(\Delta_{k}=\Phi^{-1}(\pi_{0k})\)</span>, <span class="math inline">\(\Delta_{j}^{1}=\Phi^{-1}(\pi_{0j})\)</span>, <span class="math inline">\(\Delta_{j}^{2}=\Phi^{-1}(\pi_{0j}+\pi_{1j})\)</span>,
<span class="math inline">\(\Delta_{k}^{1}=\Phi^{-1}(\pi_{0k})\)</span>,
<span class="math inline">\(\Delta_{k}^{2}=\Phi^{-1}(\pi_{0k}+\pi_{1k})\)</span>,</p>
<p><span class="math display">\[
\Sigma_{3a}(r)=
\begin{pmatrix}
1 &amp; 0 &amp; \frac{r}{\sqrt{2}} \\
0 &amp; 1 &amp; -\frac{r}{\sqrt{2}} \\
\frac{r}{\sqrt{2}} &amp; -\frac{r}{\sqrt{2}} &amp; 1
\end{pmatrix}, \;\;\;
\Sigma_{3b}(r)=
\begin{pmatrix}
1 &amp; \frac{1}{\sqrt{2}} &amp; \frac{r}{\sqrt{2}}\\
\frac{1}{\sqrt{2}} &amp; 1 &amp; r \\
\frac{r}{\sqrt{2}} &amp; r &amp; 1
\end{pmatrix}, \;\;\;
\Sigma_{3c}(r)=
\begin{pmatrix}
1 &amp; -r &amp; \frac{1}{\sqrt{2}} \\
-r &amp; 1 &amp; -\frac{r}{\sqrt{2}} \\
\frac{1}{\sqrt{2}} &amp; -\frac{r}{\sqrt{2}} &amp; 1
\end{pmatrix},
\]</span></p>
<p><span class="math display">\[
\Sigma_{3d}(r)=
\begin{pmatrix}
1 &amp; 0 &amp; -\frac{1}{\sqrt{2}} \\
0 &amp; 1 &amp; -\frac{r}{\sqrt{2}} \\
-\frac{1}{\sqrt{2}} &amp; -\frac{r}{\sqrt{2}} &amp; 1
\end{pmatrix}, \;\;\;
\Sigma_{3e}(r)=
\begin{pmatrix}
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; r \\
0 &amp; r &amp; 1
\end{pmatrix},  \;\;\;
\Sigma_{4a}(r)=
\begin{pmatrix}
1 &amp; 0 &amp; 0 &amp; \frac{r}{\sqrt{2}} \\
0 &amp; 1 &amp; -r &amp; \frac{r}{\sqrt{2}} \\
0 &amp; -r &amp; 1 &amp; -\frac{1}{\sqrt{2}} \\
\frac{r}{\sqrt{2}} &amp; \frac{r}{\sqrt{2}} &amp; -\frac{1}{\sqrt{2}}
&amp; 1
\end{pmatrix},
\]</span></p>
<p><span class="math display">\[
\Sigma_{4b}(r)=
\begin{pmatrix}
1 &amp; 0 &amp; r &amp; \frac{r}{\sqrt{2}} \\
0 &amp; 1 &amp; 0 &amp; \frac{r}{\sqrt{2}} \\
r &amp; 0 &amp; 1 &amp; \frac{1}{\sqrt{2}} \\
\frac{r}{\sqrt{2}} &amp; \frac{r}{\sqrt{2}} &amp; \frac{1}{\sqrt{2}}
&amp; 1
\end{pmatrix}, \;\;\;
\Sigma_{4c}(r)=
\begin{pmatrix}
1 &amp; 0 &amp; \frac{1}{\sqrt{2}} &amp; -\frac{r}{\sqrt{2}} \\
0 &amp; 1 &amp; -\frac{r}{\sqrt{2}} &amp; \frac{1}{\sqrt{2}} \\
\frac{1}{\sqrt{2}} &amp; -\frac{r}{\sqrt{2}} &amp; 1 &amp; -r \\
-\frac{r}{\sqrt{2}} &amp; \frac{1}{\sqrt{2}} &amp; -r &amp; 1
\end{pmatrix}\;\;\text{and}\;\;
\Sigma_{4d}(r)=
\begin{pmatrix}
1 &amp; r &amp; \frac{1}{\sqrt{2}} &amp; \frac{r}{\sqrt{2}} \\
r &amp; 1 &amp; \frac{r}{\sqrt{2}} &amp; \frac{1}{\sqrt{2}} \\
\frac{1}{\sqrt{2}} &amp; \frac{r}{\sqrt{2}} &amp; 1 &amp; r \\
\frac{r}{\sqrt{2}} &amp; \frac{1}{\sqrt{2}} &amp; r &amp; 1
\end{pmatrix}.
\]</span></p>
</div>
<div id="estimation-methods" class="section level1">
<h1>Estimation methods</h1>
<p>Given the form of bridge function <span class="math inline">\(F\)</span>, obtaining a moment-based estimation
<span class="math inline">\(\widehat \sigma_{jk}\)</span> requires
inversion of <span class="math inline">\(F\)</span>.
<code>latentcor</code> implements two methods for calculation of the
inversion:</p>
<ul>
<li><code>method = &quot;original&quot;</code> <a href="#original">Subsection
describing original method and relevant parameter
<code>tol</code></a></li>
<li><code>method = &quot;approx&quot;</code> <a href="#approx">Subsection
describing approximation method and relevant parameter
<code>ratio</code></a></li>
</ul>
<p>Both methods calculate inverse bridge function applied to each
element of sample Kendall’s <span class="math inline">\(\tau\)</span>
matrix. Because the calculation is performed point-wise (separately for
each pair of variables), the resulting point-wise estimator of
correlation matrix may not be positive semi-definite.
<code>latentcor</code> performs projection of the pointwise-estimator to
the space of positive semi-definite matrices, and allows for shrinkage
towards identity matrix using the parameter <code>nu</code> (see <a href="#shrinkage">Subsection describing adjustment of point-wise
estimator and relevant parameter <code>nu</code></a>).</p>
<div id="original" class="section level2">
<h2>Original method (<code>method = &quot;original&quot;</code>)</h2>
<p>Original estimation approach relies on numerical inversion of <span class="math inline">\(F\)</span> based on solving uni-root optimization
problem. Given the calculated <span class="math inline">\(\widehat
\tau_{jk}\)</span> (sample Kendall’s <span class="math inline">\(\tau\)</span> between variables <span class="math inline">\(j\)</span> and <span class="math inline">\(k\)</span>), the estimate of latent correlation
<span class="math inline">\(\widehat \sigma_{jk}\)</span> is obtained by
calling <code>optimize</code> function to solve the following
optimization problem: <span class="math display">\[
\widehat r_{jk} = \arg\min_{r} \{F(r) - \widehat \tau_{jk}\}^2.
\]</span> The parameter <code>tol</code> controls the desired accuracy
of the minimizer and is passed to <code>optimize</code>, with the
default precision of 1e-8:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a>estimate <span class="ot">=</span> <span class="fu">latentcor</span>(X, <span class="at">types =</span> <span class="fu">c</span>(<span class="st">&quot;con&quot;</span>, <span class="st">&quot;bin&quot;</span>, <span class="st">&quot;ter&quot;</span>, <span class="st">&quot;tru&quot;</span>), <span class="at">method =</span> <span class="st">&quot;original&quot;</span>, <span class="at">tol =</span> <span class="fl">1e-8</span>)</span></code></pre></div>
<p><strong><em>Algorithm for Original method</em></strong></p>
<p><strong>Input</strong>: <span class="math inline">\(F(r)=F(r,
\mathbf{\Delta})\)</span> - bridge function based on the type of
variables <span class="math inline">\(j\)</span>, <span class="math inline">\(k\)</span></p>
<ul>
<li>Step 1. Calculate <span class="math inline">\(\hat{\tau}_{jk}\)</span> using (1).</li>
</ul>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a>estimate<span class="sc">$</span>K</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a><span class="co">#&gt;           [,1]      [,2]      [,3]      [,4]</span></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a><span class="co">#&gt; [1,] 1.0000000 0.1826263 0.2347475 0.2963636</span></span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a><span class="co">#&gt; [2,] 0.1826263 1.0000000 0.2121212 0.1866667</span></span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a><span class="co">#&gt; [3,] 0.2347475 0.2121212 1.0000000 0.2842424</span></span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a><span class="co">#&gt; [4,] 0.2963636 0.1866667 0.2842424 1.0000000</span></span></code></pre></div>
<ul>
<li>Step 2. For binary/truncated variable <span class="math inline">\(j\)</span>, set <span class="math inline">\(\hat{\mathbf{\Delta}}_{j}=\hat{\Delta}_{j}=\Phi^{-1}(\pi_{0j})\)</span>
with <span class="math inline">\(\pi_{0j}=\sum_{i=1}^{n}\frac{I(x_{ij}=0)}{n}\)</span>.
For ternary variable <span class="math inline">\(j\)</span>, set <span class="math inline">\(\hat{\mathbf{\Delta}}_{j}=(\hat{\Delta}_{j}^{1},
\hat{\Delta}_{j}^{2})\)</span> where <span class="math inline">\(\hat{\Delta}_{j}^{1}=\Phi^{-1}(\pi_{0j})\)</span>
and <span class="math inline">\(\hat{\Delta}_{j}^{2}=\Phi^{-1}(\pi_{0j}+\pi_{1j})\)</span>
with <span class="math inline">\(\pi_{0j}=\sum_{i=1}^{n}\frac{I(x_{ij}=0)}{n}\)</span>
and <span class="math inline">\(\pi_{1j}=\sum_{i=1}^{n}\frac{I(x_{ij}=1)}{n}\)</span>.</li>
</ul>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a>estimate<span class="sc">$</span>zratios</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a><span class="co">#&gt; [[1]]</span></span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a><span class="co">#&gt; [1] NA</span></span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a><span class="co">#&gt; [[2]]</span></span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a><span class="co">#&gt; [1] 0.5</span></span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb9-8"><a href="#cb9-8" tabindex="-1"></a><span class="co">#&gt; [[3]]</span></span>
<span id="cb9-9"><a href="#cb9-9" tabindex="-1"></a><span class="co">#&gt; [1] 0.3 0.8</span></span>
<span id="cb9-10"><a href="#cb9-10" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb9-11"><a href="#cb9-11" tabindex="-1"></a><span class="co">#&gt; [[4]]</span></span>
<span id="cb9-12"><a href="#cb9-12" tabindex="-1"></a><span class="co">#&gt; [1] 0.5</span></span></code></pre></div>
<ul>
<li>Compute <span class="math inline">\(F^{-1}(\hat{\tau}_{jk})\)</span>
as <span class="math inline">\(\hat{r}_{jk}=argmin\{F(r)-\hat{\tau}_{jk}\}^{2}\)</span>
solved via <code>optimize</code> function in <em>R</em> with accuracy
<code>tol</code>.</li>
</ul>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a>estimate<span class="sc">$</span>Rpointwise</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a><span class="co">#&gt;           [,1]      [,2]      [,3]      [,4]</span></span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a><span class="co">#&gt; [1,] 1.0000000 0.4001521 0.4291095 0.5239691</span></span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a><span class="co">#&gt; [2,] 0.4001521 1.0000000 0.5454664 0.4722794</span></span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a><span class="co">#&gt; [3,] 0.4291095 0.5454664 1.0000000 0.5952768</span></span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a><span class="co">#&gt; [4,] 0.5239691 0.4722794 0.5952768 1.0000000</span></span></code></pre></div>
</div>
<div id="approx" class="section level2">
<h2>Approximation method (<code>method = &quot;approx&quot;</code>)</h2>
<p>A faster approximation method is based on multi-linear interpolation
of pre-computed inverse bridge function on a fixed grid of points <span class="citation">(Yoon, Müller, and Gaynanova 2021)</span>. This is
possible as the inverse bridge function is an analytic function of at
most 5 parameters:</p>
<ul>
<li>Kendall’s <span class="math inline">\(\tau\)</span></li>
<li>Proportion of zeros in the 1st variable</li>
<li>(Possibly) proportion of zeros and ones in the 1st variable</li>
<li>(Possibly) proportion of zeros in the 2nd variable</li>
<li>(Possibly) proportion of zeros and ones in the 2nd variable</li>
</ul>
<p>In short, d-dimensional multi-linear interpolation uses a weighted
average of <span class="math inline">\(2^{d}\)</span> neighbors to
approximate the function values at the points within the d-dimensional
cube of the neighbors, and to perform interpolation,
<code>latentcor</code> takes advantage of the R package
<code>chebpol</code> <span class="citation">(Gaure 2019)</span>. This
approximation method has been first described in <span class="citation">(Yoon, Müller, and Gaynanova 2021)</span> for
continuous/binary/truncated cases. In <code>latentcor</code>, we
additionally implement ternary case, and optimize the choice of grid as
well as interpolation boundary for faster computations with smaller
memory footprint.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="co">#estimate = latentcor(X, types = c(&quot;con&quot;, &quot;bin&quot;, &quot;ter&quot;, &quot;tru&quot;), method = &quot;approx&quot;)</span></span></code></pre></div>
<p><strong><em>Algorithm for Approximation method </em></strong></p>
<p><strong>Input</strong>: Let <span class="math inline">\(\check{g}=h(g)\)</span>, pre-computed values <span class="math inline">\(F^{-1}(h^{-1}(\check{g}))\)</span> on a fixed grid
<span class="math inline">\(\check{g}\in\check{\cal{G}}\)</span> based
on the type of variables <span class="math inline">\(j\)</span> and
<span class="math inline">\(k\)</span>. For binary/continuous case,
<span class="math inline">\(\check{g}=(\check{\tau}_{jk},
\check{\Delta}_{j})\)</span>; for binary/binary case, <span class="math inline">\(\check{g}=(\check{\tau}_{jk}, \check{\Delta}_{j},
\check{\Delta}_{k})\)</span>; for truncated/continuous case, <span class="math inline">\(\check{g}=(\check{\tau}_{jk},
\check{\Delta}_{j})\)</span>; for truncated/truncated case, <span class="math inline">\(\check{g}=(\check{\tau}_{jk}, \check{\Delta}_{j},
\check{\Delta}_{k})\)</span>; for ternary/continuous case, <span class="math inline">\(\check{g}=(\check{\tau}_{jk},
\check{\Delta}_{j}^{1}, \check{\Delta}_{j}^{2})\)</span>; for
ternary/binary case, <span class="math inline">\(\check{g}=(\check{\tau}_{jk},
\check{\Delta}_{j}^{1}, \check{\Delta}_{j}^{2},
\check{\Delta}_{k})\)</span>; for ternary/truncated case, <span class="math inline">\(\check{g}=(\check{\tau}_{jk},
\check{\Delta}_{j}^{1}, \check{\Delta}_{j}^{2},
\check{\Delta}_{k})\)</span>; for ternay/ternary case, <span class="math inline">\(\check{g}=(\check{\tau}_{jk},
\check{\Delta}_{j}^{1}, \check{\Delta}_{j}^{2}, \check{\Delta}_{k}^{1},
\check{\Delta}_{k}^{2})\)</span>.</p>
<ul>
<li><p>Step 1 and Step 2 same as Original method.</p></li>
<li><p>Step 3. If <span class="math inline">\(|\hat{\tau}_{jk}|\le
\mbox{ratio}\times \bar{\tau}_{jk}(\cdot)\)</span>, apply interpolation;
otherwise apply Original method.</p></li>
</ul>
<p>To avoid interpolation in areas with high approximation errors close
to the boundary, we use hybrid scheme in Step 3. The parameter
<code>ratio</code> controls the size of the region where the
interpolation is performed (<code>ratio = 0</code> means no
interpolation, <code>ratio = 1</code> means interpolation is always
performed). For the derivation of approximate bound for BC, BB, TC, TB,
TT cases see <span class="citation">Yoon, Müller, and Gaynanova
(2021)</span>. The derivation of approximate bound for NC, NB, NN, NT
case is in the Appendix.</p>
<p><span class="math display">\[
\bar{\tau}_{jk}(\cdot)=
\begin{cases}
2\pi_{0j}(1-\pi_{0j})  &amp;   for \; BC \; case\\
2\min(\pi_{0j},\pi_{0k})\{1-\max(\pi_{0j}, \pi_{0k})\}  &amp;   for \;
BB \; case\\
2\{\pi_{0j}(1-\pi_{0j})+\pi_{1j}(1-\pi_{0j}-\pi_{1j})\}  &amp;   for \;
NC \; case\\
2\min(\pi_{0j}(1-\pi_{0j})+\pi_{1j}(1-\pi_{0j}-\pi_{1j}),\pi_{0k}(1-\pi_{0k}))  &amp;   for
\; NB \; case\\
2\min(\pi_{0j}(1-\pi_{0j})+\pi_{1j}(1-\pi_{0j}-\pi_{1j}), \\
\;\;\;\;\;\;\;\;\;\;\pi_{0k}(1-\pi_{0k})+\pi_{1k}(1-\pi_{0k}-\pi_{1k}))  &amp;   for
\; NN \; case\\
1-(\pi_{0j})^{2}  &amp;   for \; TC \; case\\
2\max(\pi_{0k},1-\pi_{0k})\{1-\max(\pi_{0k},1-\pi_{0k},\pi_{0j})\}  &amp;   for
\; TB \; case\\
1-\{\max(\pi_{0j},\pi_{0k},\pi_{1k},1-\pi_{0k}-\pi_{1k})\}^{2}  &amp;   for
\; TN \; case\\
1-\{\max(\pi_{0j},\pi_{0k})\}^{2}  &amp;   for \; TT \; case\\
\end{cases}
\]</span></p>
<p>By default, <code>latentcor</code> uses <code>ratio = 0.9</code> as
this value was recommended in <span class="citation">Yoon, Müller, and
Gaynanova (2021)</span> having a good balance of accuracy and
computational speed. This value, however, can be modified by the
user.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="co">#latentcor(X, types = c(&quot;con&quot;, &quot;bin&quot;, &quot;ter&quot;, &quot;tru&quot;), method = &quot;approx&quot;, ratio = 0.99)$R</span></span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a><span class="co">#latentcor(X, types = c(&quot;con&quot;, &quot;bin&quot;, &quot;ter&quot;, &quot;tru&quot;), method = &quot;approx&quot;, ratio = 0.4)$R</span></span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a><span class="fu">latentcor</span>(X, <span class="at">types =</span> <span class="fu">c</span>(<span class="st">&quot;con&quot;</span>, <span class="st">&quot;bin&quot;</span>, <span class="st">&quot;ter&quot;</span>, <span class="st">&quot;tru&quot;</span>), <span class="at">method =</span> <span class="st">&quot;original&quot;</span>)<span class="sc">$</span>R</span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a><span class="co">#&gt;           [,1]      [,2]      [,3]      [,4]</span></span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a><span class="co">#&gt; [1,] 1.0000000 0.3997519 0.4286803 0.5234451</span></span>
<span id="cb12-6"><a href="#cb12-6" tabindex="-1"></a><span class="co">#&gt; [2,] 0.3997519 1.0000000 0.5449209 0.4718071</span></span>
<span id="cb12-7"><a href="#cb12-7" tabindex="-1"></a><span class="co">#&gt; [3,] 0.4286803 0.5449209 1.0000000 0.5946815</span></span>
<span id="cb12-8"><a href="#cb12-8" tabindex="-1"></a><span class="co">#&gt; [4,] 0.5234451 0.4718071 0.5946815 1.0000000</span></span></code></pre></div>
<p>The lower is the <code>ratio</code>, the closer is the approximation
method to original method (with <code>ratio = 0</code> being equivalent
to <code>method = &quot;original&quot;</code>), but also the higher is the cost of
computations.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="fu">library</span>(microbenchmark)</span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a><span class="co">#microbenchmark(latentcor(X, types = c(&quot;con&quot;, &quot;bin&quot;, &quot;ter&quot;, &quot;tru&quot;), method = &quot;approx&quot;, ratio = 0.99)$R)</span></span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a><span class="co">#microbenchmark(latentcor(X, types = c(&quot;con&quot;, &quot;bin&quot;, &quot;ter&quot;, &quot;tru&quot;), method = &quot;approx&quot;, ratio = 0.4)$R)</span></span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a><span class="fu">microbenchmark</span>(<span class="fu">latentcor</span>(X, <span class="at">types =</span> <span class="fu">c</span>(<span class="st">&quot;con&quot;</span>, <span class="st">&quot;bin&quot;</span>, <span class="st">&quot;ter&quot;</span>, <span class="st">&quot;tru&quot;</span>), <span class="at">method =</span> <span class="st">&quot;original&quot;</span>)<span class="sc">$</span>R)</span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a><span class="co">#&gt; Unit: milliseconds</span></span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a><span class="co">#&gt;                                                                        expr</span></span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a><span class="co">#&gt;  latentcor(X, types = c(&quot;con&quot;, &quot;bin&quot;, &quot;ter&quot;, &quot;tru&quot;), method = &quot;original&quot;)$R</span></span>
<span id="cb13-8"><a href="#cb13-8" tabindex="-1"></a><span class="co">#&gt;       min       lq     mean   median       uq      max neval</span></span>
<span id="cb13-9"><a href="#cb13-9" tabindex="-1"></a><span class="co">#&gt;  12.29274 12.38659 12.86126 12.59087 13.00323 16.91262   100</span></span></code></pre></div>
<p><strong>Rescaled Grid for Interpolation</strong></p>
<p>Since <span class="math inline">\(|\hat{\tau}|\le
\bar{\tau}\)</span>, the grid does not need to cover the whole domain
<span class="math inline">\(\tau\in[-1, 1]\)</span>. To optimize memory
associated with storing the grid, we rescale <span class="math inline">\(\tau\)</span> as follows: <span class="math inline">\(\check{\tau}_{jk}=\tau_{jk}/\bar{\tau}_{jk}\in[-1,
1]\)</span>, where <span class="math inline">\(\bar{\tau}_{jk}\)</span>
is as defined above.</p>
<p>In addition, for ternary variable <span class="math inline">\(j\)</span>, it always holds that <span class="math inline">\(\Delta_{j}^{2}&gt;\Delta_{j}^{1}\)</span> since
<span class="math inline">\(\Delta_{j}^{1}=\Phi^{-1}(\pi_{0j})\)</span>
and <span class="math inline">\(\Delta_{j}^{2}=\Phi^{-1}(\pi_{0j}+\pi_{1j})\)</span>.
Thus, the grid should not cover the the area corresponding to <span class="math inline">\(\Delta_{j}^{2}\le\Delta_{j}^{1}\)</span>. We thus
rescale as follows: <span class="math inline">\(\check{\Delta}_{j}^{1}=\Delta_{j}^{1}/\Delta_{j}^{2}\in[0,
1]\)</span>; <span class="math inline">\(\check{\Delta}_{j}^{2}=\Delta_{j}^{2}\in[0,
1]\)</span>.</p>
<p><strong>Speed Comparison</strong></p>
<p>To illustrate the speed improvement by
<code>method = &quot;approx&quot;</code>, we plot the run time scaling behavior of
<code>method = &quot;approx&quot;</code> and <code>method = &quot;original&quot;</code>
(setting <code>types</code> for <code>gen_data</code> by replicating
<code>c(&quot;con&quot;, &quot;bin&quot;, &quot;ter&quot;, &quot;tru&quot;)</code> multiple times) with
increasing dimensions <span class="math inline">\(p = [20, 40, 100, 200,
400]\)</span> at sample size <span class="math inline">\(n =
100\)</span> using simulation data. Figure below summarizes the observed
scaling in a log-log plot. For both methods we observe the expected
<span class="math inline">\(O(p^2)\)</span> scaling behavior with
dimension p, i.e., a linear scaling in the log-log plot. However,
<code>method = &quot;approx&quot;</code> is at least one order of magnitude faster
than <code>method = &quot;original&quot;</code> independent of the dimension of
the problem.</p>
<p><img role="img" src="data:image/png;base64,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" /></p>
</div>
<div id="shrinkage" class="section level2">
<h2>Adjustment of pointwise-estimator for positive-definiteness</h2>
<p>Since the estimation is performed point-wise, the resulting matrix of
estimated latent correlations is not guaranteed to be positive
semi-definite. For example, this could be expected when the sample size
is small (and so the estimation error for each pairwise correlation is
larger)</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="st">&quot;234820&quot;</span>)</span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a>X <span class="ot">=</span> <span class="fu">gen_data</span>(<span class="at">n =</span> <span class="dv">6</span>, <span class="at">types =</span> <span class="fu">c</span>(<span class="st">&quot;con&quot;</span>, <span class="st">&quot;bin&quot;</span>, <span class="st">&quot;ter&quot;</span>, <span class="st">&quot;tru&quot;</span>))<span class="sc">$</span>X</span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a>X</span>
<span id="cb14-4"><a href="#cb14-4" tabindex="-1"></a><span class="co">#&gt;             [,1] [,2] [,3]      [,4]</span></span>
<span id="cb14-5"><a href="#cb14-5" tabindex="-1"></a><span class="co">#&gt; [1,] -0.16632675    1    1 0.1478548</span></span>
<span id="cb14-6"><a href="#cb14-6" tabindex="-1"></a><span class="co">#&gt; [2,] -0.61463940    0    0 0.0000000</span></span>
<span id="cb14-7"><a href="#cb14-7" tabindex="-1"></a><span class="co">#&gt; [3,]  0.02495623    1    2 1.3444076</span></span>
<span id="cb14-8"><a href="#cb14-8" tabindex="-1"></a><span class="co">#&gt; [4,]  1.03744038    0    0 0.0000000</span></span>
<span id="cb14-9"><a href="#cb14-9" tabindex="-1"></a><span class="co">#&gt; [5,] -0.73599650    0    1 0.0000000</span></span>
<span id="cb14-10"><a href="#cb14-10" tabindex="-1"></a><span class="co">#&gt; [6,] -1.74626874    1    1 0.1778577</span></span>
<span id="cb14-11"><a href="#cb14-11" tabindex="-1"></a>out <span class="ot">=</span> <span class="fu">latentcor</span>(X, <span class="at">types =</span> <span class="fu">c</span>(<span class="st">&quot;con&quot;</span>, <span class="st">&quot;bin&quot;</span>, <span class="st">&quot;ter&quot;</span>, <span class="st">&quot;tru&quot;</span>))</span>
<span id="cb14-12"><a href="#cb14-12" tabindex="-1"></a>out<span class="sc">$</span>Rpointwise</span>
<span id="cb14-13"><a href="#cb14-13" tabindex="-1"></a><span class="co">#&gt;            [,1]       [,2]       [,3]      [,4]</span></span>
<span id="cb14-14"><a href="#cb14-14" tabindex="-1"></a><span class="co">#&gt; [1,]  1.0000000 -0.1477240 -0.1254816 0.0000000</span></span>
<span id="cb14-15"><a href="#cb14-15" tabindex="-1"></a><span class="co">#&gt; [2,] -0.1477240  1.0000000  0.9983941 0.9990000</span></span>
<span id="cb14-16"><a href="#cb14-16" tabindex="-1"></a><span class="co">#&gt; [3,] -0.1254816  0.9983941  1.0000000 0.9987533</span></span>
<span id="cb14-17"><a href="#cb14-17" tabindex="-1"></a><span class="co">#&gt; [4,]  0.0000000  0.9990000  0.9987533 1.0000000</span></span>
<span id="cb14-18"><a href="#cb14-18" tabindex="-1"></a><span class="fu">eigen</span>(out<span class="sc">$</span>Rpointwise)<span class="sc">$</span>values</span>
<span id="cb14-19"><a href="#cb14-19" tabindex="-1"></a><span class="co">#&gt; [1]  3.009835688  1.000242414  0.001632933 -0.011711035</span></span></code></pre></div>
<p><code>latentcor</code> automatically corrects the pointwise estimator
to be positive definite by making two adjustments. First, if
<code>Rpointwise</code> has smallest eigenvalue less than zero, the
<code>latentcor</code> projects this matrix to the nearest positive
semi-definite matrix. The user is notified of this adjustment through
the message (supressed in previous code chunk), e.g.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a>out <span class="ot">=</span> <span class="fu">latentcor</span>(X, <span class="at">types =</span> <span class="fu">c</span>(<span class="st">&quot;con&quot;</span>, <span class="st">&quot;bin&quot;</span>, <span class="st">&quot;ter&quot;</span>, <span class="st">&quot;tru&quot;</span>))</span></code></pre></div>
<p>Second, <code>latentcor</code> shrinks the adjusted matrix of
correlations towards identity matrix using the parameter <span class="math inline">\(\nu\)</span> with default value of 0.001
(<code>nu = 0.001</code>), so that the resulting <code>R</code> is
strictly positive definite with the minimal eigenvalue being greater or
equal to <span class="math inline">\(\nu\)</span>. That is <span class="math display">\[
R = (1 - \nu) \widetilde R + \nu I,
\]</span> where <span class="math inline">\(\widetilde R\)</span> is the
nearest positive semi-definite matrix to <code>Rpointwise</code>.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a>out <span class="ot">=</span> <span class="fu">latentcor</span>(X, <span class="at">types =</span> <span class="fu">c</span>(<span class="st">&quot;con&quot;</span>, <span class="st">&quot;bin&quot;</span>, <span class="st">&quot;ter&quot;</span>, <span class="st">&quot;tru&quot;</span>), <span class="at">nu =</span> <span class="fl">0.001</span>)</span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a>out<span class="sc">$</span>Rpointwise</span>
<span id="cb16-3"><a href="#cb16-3" tabindex="-1"></a><span class="co">#&gt;            [,1]       [,2]       [,3]      [,4]</span></span>
<span id="cb16-4"><a href="#cb16-4" tabindex="-1"></a><span class="co">#&gt; [1,]  1.0000000 -0.1477240 -0.1254816 0.0000000</span></span>
<span id="cb16-5"><a href="#cb16-5" tabindex="-1"></a><span class="co">#&gt; [2,] -0.1477240  1.0000000  0.9983941 0.9990000</span></span>
<span id="cb16-6"><a href="#cb16-6" tabindex="-1"></a><span class="co">#&gt; [3,] -0.1254816  0.9983941  1.0000000 0.9987533</span></span>
<span id="cb16-7"><a href="#cb16-7" tabindex="-1"></a><span class="co">#&gt; [4,]  0.0000000  0.9990000  0.9987533 1.0000000</span></span>
<span id="cb16-8"><a href="#cb16-8" tabindex="-1"></a>out<span class="sc">$</span>R</span>
<span id="cb16-9"><a href="#cb16-9" tabindex="-1"></a><span class="co">#&gt;              [,1]       [,2]       [,3]         [,4]</span></span>
<span id="cb16-10"><a href="#cb16-10" tabindex="-1"></a><span class="co">#&gt; [1,]  1.000000000 -0.1462282 -0.1245497 -0.002133664</span></span>
<span id="cb16-11"><a href="#cb16-11" tabindex="-1"></a><span class="co">#&gt; [2,] -0.146228204  1.0000000  0.9987604  0.988550037</span></span>
<span id="cb16-12"><a href="#cb16-12" tabindex="-1"></a><span class="co">#&gt; [3,] -0.124549686  0.9987604  1.0000000  0.991469239</span></span>
<span id="cb16-13"><a href="#cb16-13" tabindex="-1"></a><span class="co">#&gt; [4,] -0.002133664  0.9885500  0.9914692  1.000000000</span></span></code></pre></div>
<p>As a result, <code>R</code> and <code>Rpointwise</code> could be
quite different when sample size <span class="math inline">\(n\)</span>
is small. When <span class="math inline">\(n\)</span> is large and <span class="math inline">\(p\)</span> is moderate, the difference is
typically driven by parameter <code>nu</code>.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="st">&quot;234820&quot;</span>)</span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a>X <span class="ot">=</span> <span class="fu">gen_data</span>(<span class="at">n =</span> <span class="dv">100</span>, <span class="at">types =</span> <span class="fu">c</span>(<span class="st">&quot;con&quot;</span>, <span class="st">&quot;bin&quot;</span>, <span class="st">&quot;ter&quot;</span>, <span class="st">&quot;tru&quot;</span>))<span class="sc">$</span>X</span>
<span id="cb17-3"><a href="#cb17-3" tabindex="-1"></a>out <span class="ot">=</span> <span class="fu">latentcor</span>(X, <span class="at">types =</span> <span class="fu">c</span>(<span class="st">&quot;con&quot;</span>, <span class="st">&quot;bin&quot;</span>, <span class="st">&quot;ter&quot;</span>, <span class="st">&quot;tru&quot;</span>), <span class="at">nu =</span> <span class="fl">0.001</span>)</span>
<span id="cb17-4"><a href="#cb17-4" tabindex="-1"></a>out<span class="sc">$</span>Rpointwise</span>
<span id="cb17-5"><a href="#cb17-5" tabindex="-1"></a><span class="co">#&gt;           [,1]      [,2]      [,3]      [,4]</span></span>
<span id="cb17-6"><a href="#cb17-6" tabindex="-1"></a><span class="co">#&gt; [1,] 1.0000000 0.4001181 0.4288656 0.5232826</span></span>
<span id="cb17-7"><a href="#cb17-7" tabindex="-1"></a><span class="co">#&gt; [2,] 0.4001181 1.0000000 0.5471851 0.4710536</span></span>
<span id="cb17-8"><a href="#cb17-8" tabindex="-1"></a><span class="co">#&gt; [3,] 0.4288656 0.5471851 1.0000000 0.5830118</span></span>
<span id="cb17-9"><a href="#cb17-9" tabindex="-1"></a><span class="co">#&gt; [4,] 0.5232826 0.4710536 0.5830118 1.0000000</span></span>
<span id="cb17-10"><a href="#cb17-10" tabindex="-1"></a>out<span class="sc">$</span>R</span>
<span id="cb17-11"><a href="#cb17-11" tabindex="-1"></a><span class="co">#&gt;           [,1]      [,2]      [,3]      [,4]</span></span>
<span id="cb17-12"><a href="#cb17-12" tabindex="-1"></a><span class="co">#&gt; [1,] 1.0000000 0.3997180 0.4284367 0.5227594</span></span>
<span id="cb17-13"><a href="#cb17-13" tabindex="-1"></a><span class="co">#&gt; [2,] 0.3997180 1.0000000 0.5466379 0.4705825</span></span>
<span id="cb17-14"><a href="#cb17-14" tabindex="-1"></a><span class="co">#&gt; [3,] 0.4284367 0.5466379 1.0000000 0.5824288</span></span>
<span id="cb17-15"><a href="#cb17-15" tabindex="-1"></a><span class="co">#&gt; [4,] 0.5227594 0.4705825 0.5824288 1.0000000</span></span></code></pre></div>
</div>
</div>
<div id="appendix" class="section level1">
<h1>Appendix</h1>
<div id="derivation-of-bridge-function-f-for-ternarytruncated-case" class="section level2">
<h2>Derivation of bridge function <span class="math inline">\(F\)</span>
for ternary/truncated case</h2>
<p>Without loss of generality, let <span class="math inline">\(j=1\)</span> and <span class="math inline">\(k=2\)</span>. By the definition of Kendall’s <span class="math inline">\(\tau\)</span>, <span class="math display">\[
    \tau_{12}=E(\hat{\tau}_{12})=E[\frac{2}{n(n-1)}\sum_{1\leq i\leq
i&#39; \leq n} sign\{(X_{i1}-X_{i&#39;1})(X_{i2}-X_{i&#39;2})\}].
\]</span> Since <span class="math inline">\(X_{1}\)</span> is ternary,
<span class="math display">\[\begin{align}
    &amp;sign(X_{1}-X_{1}&#39;) \nonumber\\
=&amp;[I(U_{1}&gt;C_{11},U_{1}&#39;\leq
C_{11})+I(U_{1}&gt;C_{12},U_{1}&#39;\leq
C_{12})-I(U_{1}&gt;C_{12},U_{1}&#39;\leq C_{11})] \nonumber\\
    &amp;-[I(U_{1}\leq C_{11}, U_{1}&#39;&gt;C_{11})+I(U_{1}\leq C_{12},
U_{1}&#39;&gt;C_{12})-I(U_{1}\leq C_{11}, U_{1}&#39;&gt;C_{12})]
\nonumber\\
    =&amp;[I(U_{1}&gt;C_{11})-I(U_{1}&gt;C_{11},U_{1}&#39;&gt;C_{11})+I(U_{1}&gt;C_{12})-I(U_{1}&gt;C_{12},U_{1}&#39;&gt;C_{12})
\nonumber\\
    &amp;-I(U_{1}&gt;C_{12})+I(U_{1}&gt;C_{12},U_{1}&#39;&gt;C_{11})]
\nonumber\\
    &amp;-[I(U_{1}&#39;&gt;C_{11})-I(U_{1}&gt;C_{11},U_{1}&#39;&gt;C_{11})+I(U_{1}&#39;&gt;C_{12})-I(U_{1}&gt;C_{12},U_{1}&#39;&gt;C_{12})
\nonumber\\
    &amp;-I(U_{1}&#39;&gt;C_{12})+I(U_{1}&gt;C_{11},U_{1}&#39;&gt;C_{12})]
\nonumber\\
    =&amp;I(U_{1}&gt;C_{11})+I(U_{1}&gt;C_{12},U_{1}&#39;&gt;C_{11})-I(U_{1}&#39;&gt;C_{11})-I(U_{1}&gt;C_{11},U_{1}&#39;&gt;C_{12})
\nonumber\\
    =&amp;I(U_{1}&gt;C_{11},U_{1}&#39;\leq
C_{12})-I(U_{1}&#39;&gt;C_{11},U_{1}\leq C_{12}).
\end{align}\]</span> Since <span class="math inline">\(X_{2}\)</span> is
truncated, <span class="math inline">\(C_{1}&gt;0\)</span> and <span class="math display">\[\begin{align}
    sign(X_{2}-X_{2}&#39;)=&amp;-I(X_{2}=0,X_{2}&#39;&gt;0)+I(X_{2}&gt;0,X_{2}&#39;=0)
\nonumber\\
    &amp;+I(X_{2}&gt;0,X_{2}&#39;&gt;0)sign(X_{2}-X_{2}&#39;)
\nonumber\\
    =&amp;-I(X_{2}=0)+I(X_{2}&#39;=0)+I(X_{2}&gt;0,X_{2}&#39;&gt;0)sign(X_{2}-X_{2}&#39;).
\end{align}\]</span> Since <span class="math inline">\(f\)</span> is
monotonically increasing, <span class="math inline">\(sign(X_{2}-X_{2}&#39;)=sign(Z_{2}-Z_{2}&#39;)\)</span>,
<span class="math display">\[\begin{align}
    \tau_{12}=&amp;E[I(U_{1}&gt;C_{11},U_{1}&#39;\leq C_{12})
sign(X_{2}-X_{2}&#39;)] \nonumber\\
&amp;-E[I(U_{1}&#39;&gt;C_{11},U_{1}\leq C_{12}) sign(X_{2}-X_{2}&#39;)]
\nonumber\\
    =&amp;-E[I(U_{1}&gt;C_{11},U_{1}&#39;\leq C_{12}) I(X_{2}=0)]
\nonumber\\
    &amp;+E[I(U_{1}&gt;C_{11},U_{1}&#39;\leq C_{12}) I(X_{2}&#39;=0)]
\nonumber\\
    &amp;+E[I(U_{1}&gt;C_{11},U_{1}&#39;\leq
C_{12})I(X_{2}&gt;0,X_{2}&#39;&gt;0)sign(Z_{2}-Z_{2}&#39;)] \nonumber\\
    &amp;+E[I(U_{1}&#39;&gt;C_{11},U_{1}\leq C_{12}) I(X_{2}=0)]
\nonumber\\
    &amp;-E[I(U_{1}&#39;&gt;C_{11},U_{1}\leq C_{12}) I(X_{2}&#39;=0)]
\nonumber\\
    &amp;-E[I(U_{1}&#39;&gt;C_{11},U_{1}\leq
C_{12})I(X_{2}&gt;0,X_{2}&#39;&gt;0)sign(Z_{2}-Z_{2}&#39;)]  \nonumber\\
    =&amp;-2E[I(U_{1}&gt;C_{11},U_{1}&#39;\leq C_{12}) I(X_{2}=0)]
\nonumber\\
    &amp;+2E[I(U_{1}&gt;C_{11},U_{1}&#39;\leq C_{12}) I(X_{2}&#39;=0)]
\nonumber\\
    &amp;+E[I(U_{1}&gt;C_{11},U_{1}&#39;\leq
C_{12})I(X_{2}&gt;0,X_{2}&#39;&gt;0)sign(Z_{2}-Z_{2}&#39;)] \nonumber\\
    &amp;-E[I(U_{1}&#39;&gt;C_{11},U_{1}\leq
C_{12})I(X_{2}&gt;0,X_{2}&#39;&gt;0)sign(Z_{2}-Z_{2}&#39;)].
\end{align}\]</span> From the definition of <span class="math inline">\(U\)</span>, let <span class="math inline">\(Z_{j}=f_{j}(U_{j})\)</span> and <span class="math inline">\(\Delta_{j}=f_{j}(C_{j})\)</span> for <span class="math inline">\(j=1,2\)</span>. Using <span class="math inline">\(sign(x)=2I(x&gt;0)-1\)</span>, we obtain <span class="math display">\[\begin{align}
    \tau_{12}=&amp;-2E[I(Z_{1}&gt;\Delta_{11},Z_{1}&#39;\leq
\Delta_{12},Z_{2}\leq
\Delta_{2})]+2E[I(Z_{1}&gt;\Delta_{11},Z_{1}&#39;\leq
\Delta_{12},Z_{2}&#39;\leq \Delta_{2})] \nonumber\\
    &amp;+2E[I(Z_{1}&gt;\Delta_{11},Z_{1}&#39;\leq
\Delta_{12})I(Z_{2}&gt;\Delta_{2},Z_{2}&#39;&gt;\Delta_{2},Z_{2}-Z_{2}&#39;&gt;0)]
\nonumber\\
    &amp;-2E[I(Z_{1}&#39;&gt;\Delta_{11},Z_{1}\leq
\Delta_{12})I(Z_{2}&gt;\Delta_{2},Z_{2}&#39;&gt;\Delta_{2},Z_{2}-Z_{2}&#39;&gt;0)]
\nonumber\\
    =&amp;-2E[I(Z_{1}&gt;\Delta_{11},Z_{1}&#39;\leq \Delta_{12},
Z_{2}\leq \Delta_{2})]+2E[I(Z_{1}&gt;\Delta_{11},Z_{1}&#39;\leq
\Delta_{12}, Z_{2}&#39;\leq \Delta_{2})] \nonumber\\
    &amp;+2E[I(Z_{1}&gt;\Delta_{11},Z_{1}&#39;\leq\Delta_{12},Z_{2}&#39;&gt;\Delta_{2},Z_{2}&gt;Z_{2}&#39;)]
\nonumber\\
    &amp;-2E[I(Z_{1}&#39;&gt;\Delta_{11},Z_{1}\leq\Delta_{12},Z_{2}&#39;&gt;\Delta_{2},Z_{2}&gt;Z_{2}&#39;)].
\end{align}\]</span> Since <span class="math inline">\(\{\frac{Z_{2}&#39;-Z_{2}}{\sqrt{2}},
-Z{1}\}\)</span>, <span class="math inline">\(\{\frac{Z_{2}&#39;-Z_{2}}{\sqrt{2}},
Z{1}&#39;\}\)</span> and <span class="math inline">\(\{\frac{Z_{2}&#39;-Z_{2}}{\sqrt{2}},
-Z{2}&#39;\}\)</span> are standard bivariate normally distributed
variables with correlation <span class="math inline">\(-\frac{1}{\sqrt{2}}\)</span>, <span class="math inline">\(r/\sqrt{2}\)</span> and <span class="math inline">\(-\frac{r}{\sqrt{2}}\)</span>, respectively, by the
definition of <span class="math inline">\(\Phi_3(\cdot,\cdot,
\cdot;\cdot)\)</span> and <span class="math inline">\(\Phi_4(\cdot,\cdot, \cdot,\cdot;\cdot)\)</span> we
have <span class="math display">\[\begin{align}
    F_{NT}(r;\Delta_{j}^{1},\Delta_{j}^{2},\Delta_{k})= &amp;
-2\Phi_{3}\left\{-\Delta_{j}^{1},\Delta_{j}^{2},\Delta_{k};\begin{pmatrix}
1 &amp; 0 &amp; -r \\
0 &amp; 1 &amp; 0 \\
-r &amp; 0 &amp; 1
\end{pmatrix} \right\} \nonumber\\
    &amp;+2\Phi_{3}\left\{-\Delta_{j}^{1},\Delta_{j}^{2},\Delta_{k};\begin{pmatrix}
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; r \\
0 &amp; r &amp; 1
\end{pmatrix}\right\}\nonumber \\
    &amp;
+2\Phi_{4}\left\{-\Delta_{j}^{1},\Delta_{j}^{2},-\Delta_{k},0;\begin{pmatrix}
1 &amp; 0 &amp; 0 &amp; \frac{r}{\sqrt{2}} \\
0 &amp; 1 &amp; -r &amp; \frac{r}{\sqrt{2}} \\
0 &amp; -r &amp; 1 &amp; -\frac{1}{\sqrt{2}} \\
\frac{r}{\sqrt{2}} &amp; \frac{r}{\sqrt{2}} &amp; -\frac{1}{\sqrt{2}}
&amp; 1
\end{pmatrix}\right\} \nonumber\\
    &amp;-2\Phi_{4}\left\{-\Delta_{j}^{1},\Delta_{j}^{2},-\Delta_{k},0;\begin{pmatrix}
1 &amp; 0 &amp; r &amp; -\frac{r}{\sqrt{2}} \\
0 &amp; 1 &amp; 0 &amp; -\frac{r}{\sqrt{2}} \\
r &amp; 0 &amp; 1 &amp; -\frac{1}{\sqrt{2}} \\
-\frac{r}{\sqrt{2}} &amp; -\frac{r}{\sqrt{2}} &amp; -\frac{1}{\sqrt{2}}
&amp; 1
\end{pmatrix}\right\}.
\end{align}\]</span> Using the facts that <span class="math display">\[\begin{align}
&amp;\Phi_{4}\left\{-\Delta_{j}^{1},\Delta_{j}^{2},-\Delta_{k},0;\begin{pmatrix}
1 &amp; 0 &amp; r &amp; -\frac{r}{\sqrt{2}} \\
0 &amp; 1 &amp; 0 &amp; -\frac{r}{\sqrt{2}} \\
r &amp; 0 &amp; 1 &amp; -\frac{1}{\sqrt{2}} \\
-\frac{r}{\sqrt{2}} &amp; -\frac{r}{\sqrt{2}} &amp; -\frac{1}{\sqrt{2}}
&amp; 1
\end{pmatrix}\right\} \nonumber\\
&amp;+\Phi_{4}\left\{-\Delta_{j}^{1},\Delta_{j}^{2},-\Delta_{k},0;\begin{pmatrix}
1 &amp; 0 &amp; r &amp; \frac{r}{\sqrt{2}} \\
0 &amp; 1 &amp; 0 &amp; \frac{r}{\sqrt{2}} \\
r &amp; 0 &amp; 1 &amp; \frac{1}{\sqrt{2}} \\
\frac{r}{\sqrt{2}} &amp; \frac{r}{\sqrt{2}} &amp; \frac{1}{\sqrt{2}}
&amp; 1
\end{pmatrix}\right\} \nonumber\\
=&amp;\Phi_{3}\left\{-\Delta_{j}^{1},\Delta_{j}^{2},-\Delta_{k};\begin{pmatrix}
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; r \\
0 &amp; r &amp; 1
\end{pmatrix}\right\}
\end{align}\]</span> and <span class="math display">\[\begin{align}
&amp;\Phi_{3}\left\{-\Delta_{j}^{1},\Delta_{j}^{2},-\Delta_{k};\begin{pmatrix}
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; r \\
0 &amp; r &amp; 1
\end{pmatrix}\right\}+\Phi_{3}\left\{-\Delta_{j}^{1},\Delta_{j}^{2},\Delta_{k};\begin{pmatrix}
1 &amp; 0 &amp; -r \\
0 &amp; 1 &amp; 0 \\
-r &amp; 0 &amp; 1
\end{pmatrix} \right\} \nonumber\\
=&amp;\Phi_{2}(-\Delta_{j}^{1},\Delta_{j}^{2};0)
=\Phi(-\Delta_{j}^{1})\Phi(\Delta_{j}^{2}).
\end{align}\]</span> So that, <span class="math display">\[\begin{align}
    F_{NT}(r;\Delta_{j}^{1},\Delta_{j}^{2},\Delta_{k})= &amp;
-2\Phi(-\Delta_{j}^{1})\Phi(\Delta_{j}^{2}) \nonumber\\
    &amp;+2\Phi_{3}\left\{-\Delta_{j}^{1},\Delta_{j}^{2},\Delta_{k};\begin{pmatrix}
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; r \\
0 &amp; r &amp; 1
\end{pmatrix}\right\}\nonumber \\
    &amp;
+2\Phi_{4}\left\{-\Delta_{j}^{1},\Delta_{j}^{2},-\Delta_{k},0;\begin{pmatrix}
1 &amp; 0 &amp; 0 &amp; \frac{r}{\sqrt{2}} \\
0 &amp; 1 &amp; -r &amp; \frac{r}{\sqrt{2}} \\
0 &amp; -r &amp; 1 &amp; -\frac{1}{\sqrt{2}} \\
\frac{r}{\sqrt{2}} &amp; \frac{r}{\sqrt{2}} &amp; -\frac{1}{\sqrt{2}}
&amp; 1
\end{pmatrix}\right\} \nonumber\\
    &amp;+2\Phi_{4}\left\{-\Delta_{j}^{1},\Delta_{j}^{2},-\Delta_{k},0;\begin{pmatrix}
1 &amp; 0 &amp; r &amp; \frac{r}{\sqrt{2}} \\
0 &amp; 1 &amp; 0 &amp; \frac{r}{\sqrt{2}} \\
r &amp; 0 &amp; 1 &amp; \frac{1}{\sqrt{2}} \\
\frac{r}{\sqrt{2}} &amp; \frac{r}{\sqrt{2}} &amp; \frac{1}{\sqrt{2}}
&amp; 1
\end{pmatrix}\right\}.
\end{align}\]</span></p>
<p>It is easy to get the bridge function for truncated/ternary case by
switching <span class="math inline">\(j\)</span> and <span class="math inline">\(k\)</span>.</p>
</div>
<div id="derivation-of-approximate-bound-for-the-ternarycontinuous-case" class="section level2">
<h2>Derivation of approximate bound for the ternary/continuous case</h2>
<p>Let <span class="math inline">\(n_{0x}=\sum_{i=1}^{n_x}I(x_{i}=0)\)</span>, <span class="math inline">\(n_{2x}=\sum_{i=1}^{n_x}I(x_{i}=2)\)</span>, <span class="math inline">\(\pi_{0x}=\frac{n_{0x}}{n_{x}}\)</span> and <span class="math inline">\(\pi_{2x}=\frac{n_{2x}}{n_{x}}\)</span>, then <span class="math display">\[\begin{align}
    |\tau(\mathbf{x})|\leq &amp;
\frac{n_{0x}(n-n_{0x})+n_{2x}(n-n_{0x}-n_{2x})}{\begin{pmatrix} n \\ 2
\end{pmatrix}} \nonumber\\
    = &amp;
2\{\frac{n_{0x}}{n-1}-(\frac{n_{0x}}{n})(\frac{n_{0x}}{n-1})+\frac{n_{2x}}{n-1}-(\frac{n_{2x}}{n})(\frac{n_{0x}}{n-1})-(\frac{n_{2x}}{n})(\frac{n_{2x}}{n-1})\}
\nonumber\\
    \approx &amp;
2\{\frac{n_{0x}}{n}-(\frac{n_{0x}}{n})^2+\frac{n_{2x}}{n}-(\frac{n_{2x}}{n})(\frac{n_{0x}}{n})-(\frac{n_{2x}}{n})^2\}
\nonumber\\
    = &amp; 2\{\pi_{0x}(1-\pi_{0x})+\pi_{2x}(1-\pi_{0x}-\pi_{2x})\}
\end{align}\]</span></p>
<p>For ternary/binary and ternary/ternary cases, we combine the two
individual bounds.</p>
</div>
<div id="derivation-of-approximate-bound-for-the-ternarytruncated-case" class="section level2">
<h2>Derivation of approximate bound for the ternary/truncated case</h2>
<p>Let <span class="math inline">\(\mathbf{x}\in\mathcal{R}^{n}\)</span>
and <span class="math inline">\(\mathbf{y}\in\mathcal{R}^{n}\)</span> be
the observed <span class="math inline">\(n\)</span> realizations of
ternary and truncated variables, respectively. Let <span class="math inline">\(n_{0x}=\sum_{i=0}^{n}I(x_{i}=0)\)</span>, <span class="math inline">\(\pi_{0x}=\frac{n_{0x}}{n}\)</span>, <span class="math inline">\(n_{1x}=\sum_{i=0}^{n}I(x_{i}=1)\)</span>, <span class="math inline">\(\pi_{1x}=\frac{n_{1x}}{n}\)</span>, <span class="math inline">\(n_{2x}=\sum_{i=0}^{n}I(x_{i}=2)\)</span>, <span class="math inline">\(\pi_{2x}=\frac{n_{2x}}{n}\)</span>, <span class="math inline">\(n_{0y}=\sum_{i=0}^{n}I(y_{i}=0)\)</span>, <span class="math inline">\(\pi_{0y}=\frac{n_{0y}}{n}\)</span>, <span class="math inline">\(n_{0x0y}=\sum_{i=0}^{n}I(x_{i}=0 \;\&amp; \;
y_{i}=0)\)</span>, <span class="math inline">\(n_{1x0y}=\sum_{i=0}^{n}I(x_{i}=1 \;\&amp; \;
y_{i}=0)\)</span> and <span class="math inline">\(n_{2x0y}=\sum_{i=0}^{n}I(x_{i}=2 \;\&amp; \;
y_{i}=0)\)</span> then <span class="math display">\[\begin{align}
    |\tau(\mathbf{x}, \mathbf{y})|\leq &amp;
    \frac{\begin{pmatrix}n \\ 2\end{pmatrix}-\begin{pmatrix}n_{0x} \\
2\end{pmatrix}-\begin{pmatrix}n_{1x} \\ 2\end{pmatrix}-\begin{pmatrix}
n_{2x} \\ 2 \end{pmatrix}-\begin{pmatrix}n_{0y} \\
2\end{pmatrix}+\begin{pmatrix}n_{0x0y} \\ 2
\end{pmatrix}+\begin{pmatrix}n_{1x0y} \\
2\end{pmatrix}+\begin{pmatrix}n_{2x0y} \\
2\end{pmatrix}}{\begin{pmatrix}n \\ 2\end{pmatrix}} \nonumber
\end{align}\]</span> Since <span class="math inline">\(n_{0x0y}\leq\min(n_{0x},n_{0y})\)</span>, <span class="math inline">\(n_{1x0y}\leq\min(n_{1x},n_{0y})\)</span> and <span class="math inline">\(n_{2x0y}\leq\min(n_{2x},n_{0y})\)</span> we obtain
<span class="math display">\[\begin{align}
     |\tau(\mathbf{x}, \mathbf{y})|\leq &amp;
    \frac{\begin{pmatrix}n \\ 2\end{pmatrix}-\begin{pmatrix}n_{0x} \\
2\end{pmatrix}-\begin{pmatrix}n_{1x} \\ 2\end{pmatrix}-\begin{pmatrix}
n_{2x} \\ 2 \end{pmatrix}-\begin{pmatrix}n_{0y} \\
2\end{pmatrix}}{\begin{pmatrix}n \\ 2\end{pmatrix}} \nonumber\\
    &amp; +  \frac{\begin{pmatrix}\min(n_{0x},n_{0y}) \\ 2
\end{pmatrix}+\begin{pmatrix}\min(n_{1x},n_{0y}) \\
2\end{pmatrix}+\begin{pmatrix}\min(n_{2x},n_{0y}) \\
2\end{pmatrix}}{\begin{pmatrix}n \\ 2\end{pmatrix}} \nonumber\\
    \leq &amp; \frac{\begin{pmatrix}n \\
2\end{pmatrix}-\begin{pmatrix}\max(n_{0x},n_{1x},n_{2x},n_{0y}) \\
2\end{pmatrix}}{\begin{pmatrix}n \\ 2\end{pmatrix}} \nonumber\\
    \leq &amp;
1-\frac{\max(n_{0x},n_{1x},n_{2x},n_{0y})(\max(n_{0x},n_{1x},n_{2x},n_{0y})-1)}{n(n-1)}
\nonumber\\
    \approx &amp; 1-(\frac{\max(n_{0x},n_{1x},n_{2x},n_{0y})}{n})^{2}
\nonumber\\
    =&amp; 1-\{\max(\pi_{0x},\pi_{1x},\pi_{2x},\pi_{0y})\}^{2}
\nonumber\\
    =&amp;
1-\{\max(\pi_{0x},(1-\pi_{0x}-\pi_{2x}),\pi_{2x},\pi_{0y})\}^{2}
\end{align}\]</span></p>
<p>It is easy to get the approximate bound for truncated/ternary case by
switching <span class="math inline">\(\mathbf{x}\)</span> and <span class="math inline">\(\mathbf{y}\)</span>.</p>
</div>
</div>
<div id="references" class="section level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-croux2013robust" class="csl-entry">
Croux, Christophe, Peter Filzmoser, and Heinrich Fritz. 2013.
<span>“Robust Sparse Principal Component Analysis.”</span>
<em>Technometrics</em> 55 (2): 202–14.
</div>
<div id="ref-fan2017high" class="csl-entry">
Fan, Jianqing, Han Liu, Yang Ning, and Hui Zou. 2017. <span>“High
Dimensional Semiparametric Latent Graphical Model for Mixed
Data.”</span> <em>Journal of the Royal Statistical Society. Series B:
Statistical Methodology</em> 79 (2): 405–21.
</div>
<div id="ref-filzmoser2021pcapp" class="csl-entry">
Filzmoser, Peter, Heinrich Fritz, and Klaudius Kalcher. 2021. <em>pcaPP:
Robust PCA by Projection Pursuit</em>. <a href="https://CRAN.R-project.org/package=pcaPP">https://CRAN.R-project.org/package=pcaPP</a>.
</div>
<div id="ref-fox2019poly" class="csl-entry">
Fox, John. 2019. <em>Polycor: Polychoric and Polyserial
Correlations</em>. <a href="https://CRAN.R-project.org/package=polycor">https://CRAN.R-project.org/package=polycor</a>.
</div>
<div id="ref-R-chebpol" class="csl-entry">
Gaure, Simen. 2019. <em>Chebpol: Multivariate Interpolation</em>. <a href="https://github.com/sgaure/chebpol">https://github.com/sgaure/chebpol</a>.
</div>
<div id="ref-liu2009nonparanormal" class="csl-entry">
Liu, Han, John Lafferty, and Larry Wasserman. 2009. <span>“The
Nonparanormal: Semiparametric Estimation of High Dimensional Undirected
Graphs.”</span> <em>Journal of Machine Learning Research</em> 10 (10).
</div>
<div id="ref-quan2018rank" class="csl-entry">
Quan, Xiaoyun, James G Booth, and Martin T Wells. 2018.
<span>“Rank-Based Approach for Estimating Correlations in Mixed Ordinal
Data.”</span> <em>arXiv Preprint arXiv:1809.06255</em>.
</div>
<div id="ref-yoon2020sparse" class="csl-entry">
Yoon, Grace, Raymond J Carroll, and Irina Gaynanova. 2020. <span>“Sparse
Semiparametric Canonical Correlation Analysis for Data of Mixed
Types.”</span> <em>Biometrika</em> 107 (3): 609–25.
</div>
<div id="ref-yoon2021fast" class="csl-entry">
Yoon, Grace, Christian L Müller, and Irina Gaynanova. 2021. <span>“Fast
Computation of Latent Correlations.”</span> <em>Journal of Computational
and Graphical Statistics</em>, 1–8.
</div>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
